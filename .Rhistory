} # end rep
}
#load package
load_all()
library(dplyr)
# Settings for Simulation
n_reps <- 20
n <- 500          #number of observations
p <- 1            #number of features
#----------------------------------
# Data Generating
#----------------------------------
# 3 Scenarios:
#     A: Non-linear μ, constant σ
#     B: Nonlinear  μ, non linear heteroscetastic σ
#     C: Nonlinear μ, nonlinear heteroskedatic σ, heavy tails (Robustness Test)
scenarios <- list(
"DG_A" = list(
mu_fn = function(X) sin(2*X[,1]) + 0.5*X[,2]^2 - 0.3*X[,3],
sigma_fn = function(X) rep(1,n),
error_fn = function(n) rnorm(n)
),
"DGP_B" = list(
mu_fn    = function(X) sin(2*X[,1]) + 0.5*X[,2]^2 - 0.3*X[,3],
sigma_fn = function(X) 0.5 + 0.5 * plogis(X[,1] + 0.3*X[,2]),
error_fn = function(n) rnorm(n)
),
"DGP_C" = list(
mu_fn    = function(X) sin(2*X[,1]) + 0.5*X[,2]^2 - 0.3*X[,3],
sigma_fn = function(X) 0.5 + 0.5 * plogis(X[,1] + 0.3*X[,2]),
error_fn = function(n) rt(n, df=3)   # heavy tails
)
)
# save results
results <- list()
# -------------------------------
# Loop over scenarios
# --------------------------------
for(scn_name in names(scenarios)) {
cat("Starting Scenario:", scn_name, "\n")
scn <- scenarios[[scn_name]]
for (rep_id in 1:n_reps) {
cat(" Replication:", rep_id, "\n")
set.seed(100 + rep_id)
# generate features
x <- matrix(runif(n*p, -1,1), nrow = n, ncol = p)
cat("check 1")
# generate my, sigma and epsilon from predefined scenarios
mu_true <- scn$mu_fn(X)
sigma_true <- scn$sigma_fn(X)
epsilon <- scn$error_fn(n)
#generate target
y <- mu_true + sigma_true * epsilon
#combine into dataframe
df <- data.frame(x = x, y = y)
cat("check 2")
#generate training, validation and testsets
data_split <- random_split(df["x"], normalization = FALSE)
val_split <- data_split$validation
train_loader <- DataLoader(data_split$train)
# ------------------------------------
# Training
# ------------------------------------
cat("check 3")
model <- train(train_loader,Y , val_split,
epochs = 500,
early_stopping = TRUE
#Seed funktion in train einbauen
)
# Prediction on Test Set
} # end rep
}
?data.frame
load_all()
library(dplyr)
# Settings for Simulation
n_reps <- 20
n <- 500          #number of observations
p <- 1            #number of features
#----------------------------------
# Data Generating
#----------------------------------
# 3 Scenarios:
#     A: Non-linear μ, constant σ
#     B: Nonlinear  μ, non linear heteroscetastic σ
#     C: Nonlinear μ, nonlinear heteroskedatic σ, heavy tails (Robustness Test)
scenarios <- list(
"DG_A" = list(
mu_fn = function(X) sin(2*X[,1]) + 0.5*X[,2]^2 - 0.3*X[,3],
sigma_fn = function(X) rep(1,n),
error_fn = function(n) rnorm(n)
),
"DGP_B" = list(
mu_fn    = function(X) sin(2*X[,1]) + 0.5*X[,2]^2 - 0.3*X[,3],
sigma_fn = function(X) 0.5 + 0.5 * plogis(X[,1] + 0.3*X[,2]),
error_fn = function(n) rnorm(n)
),
"DGP_C" = list(
mu_fn    = function(X) sin(2*X[,1]) + 0.5*X[,2]^2 - 0.3*X[,3],
sigma_fn = function(X) 0.5 + 0.5 * plogis(X[,1] + 0.3*X[,2]),
error_fn = function(n) rt(n, df=3)   # heavy tails
)
)
# save results
results <- list()
# -------------------------------
# Loop over scenarios
# --------------------------------
for(scn_name in names(scenarios)) {
cat("Starting Scenario:", scn_name, "\n")
scn <- scenarios[[scn_name]]
for (rep_id in 1:n_reps) {
cat(" Replication:", rep_id, "\n")
set.seed(100 + rep_id)
# generate features
X <- matrix(runif(n*p, -1,1), nrow = n, ncol = p)
cat("check 1")
# generate my, sigma and epsilon from predefined scenarios
mu_true <- scn$mu_fn(X)
sigma_true <- scn$sigma_fn(X)
epsilon <- scn$error_fn(n)
#generate target
y <- mu_true + sigma_true * epsilon
#combine into dataframe
df <- data.frame(x = x, y = y)
cat("check 2")
#generate training, validation and testsets
data_split <- random_split(df["x"], normalization = FALSE)
val_split <- data_split$validation
train_loader <- DataLoader(data_split$train)
# ------------------------------------
# Training
# ------------------------------------
cat("check 3")
model <- train(train_loader,Y , val_split,
epochs = 500,
early_stopping = TRUE
#Seed funktion in train einbauen
)
# Prediction on Test Set
} # end rep
}
generate_data_A <- function(n) {
x <- runif(n, -1, 1)                   # Feature
mu <- sin(2 * x)                       # Erwartungswert
sigma <- rep(1, n)                      # konstante Varianz
eps <- rnorm(n)                         # Normalfehler
y <- mu + sigma * eps                   # Zielvariable
data.frame(x = x, y = y)
}
generate_data_A(1)
generate_data_A(50)
df <- generate_data_A(50)
View(df)
plot(df$x, df$y)
df <- generate_data_A(500)
View(df)
plot(df$x, df$y)
df <- generate_data_A(1000)
plot(df$x, df$y)
# Szenario A: nichtlineares µ, konstantes σ
generate_data_A <- function(n) {
x <- runif(n, -1, 1)                   # Feature
mu <- 2 *sin(x)                       # Erwartungswert
sigma <- rep(1, n)                      # konstante Varianz
eps <- rnorm(n)                         # Normalfehler
y <- mu + sigma * eps                   # Zielvariable
data.frame(x = x, y = y)
}
df <- generate_data_A(1000)
plot(df$x, df$y)
# Szenario A: nichtlineares µ, konstantes σ
generate_data_A <- function(n) {
x <- runif(n, -1, 1)                   # Feature
mu <- 2 *sin(x)                       # Erwartungswert
sigma <- rep(1, n)                      # konstante Varianz
eps <- rnorm(n)                         # Normalfehler
y <- mu + sigma * eps                   # Zielvariable
data.frame(x = x, y = y)
}
df <- generate_data_A(1000)
plot(df$x, df$y)
# Szenario A: nichtlineares µ, konstantes σ
generate_data_A <- function(n) {
x <- runif(n, -10, 10)                   # Feature
mu <- 5 *sin(x)                       # Erwartungswert
sigma <- rep(1, n)                      # konstante Varianz
eps <- rnorm(n)                         # Normalfehler
y <- mu + sigma * eps                   # Zielvariable
data.frame(x = x, y = y)
}
df <- generate_data_A(1000)
plot(df$x, df$y)
# Szenario A: nichtlineares µ, konstantes σ
generate_data_A <- function(n) {
x <- runif(n, -1, 1)                   # Feature
mu <- 5 *sin(x)                       # Erwartungswert
sigma <- rep(1, n)                      # konstante Varianz
eps <- rnorm(n)                         # Normalfehler
y <- mu + sigma * eps                   # Zielvariable
data.frame(x = x, y = y)
}
df <- generate_data_A(1000)
plot(df$x, df$y)
generate_data_B <- function(n) {
x <- runif(n, -1, 1)
mu <- sin(2 * x)
sigma <- 0.5 + 0.5 * plogis(x)          # σ hängt von x ab
eps <- rnorm(n)
y <- mu + sigma * eps
data.frame(x = x, y = y)
}
df <- generate_data_B(1000)
plot(df$x, df$y)
generate_data_B <- function(n) {
x <- runif(n, -5, 5)
mu <- sin(2 * x)
sigma <- 0.5 + 0.5 * plogis(x)          # σ hängt von x ab
eps <- rnorm(n)
y <- mu + sigma * eps
data.frame(x = x, y = y)
}
df <- generate_data_B(1000)
plot(df$x, df$y)
generate_data_C <- function(n) {
x <- runif(n, -5, 5)
mu <- sin(2 * x)
sigma <- 0.5 + 0.5 * plogis(x)
eps <- rt(n, df = 3)                    # heavy tails
y <- mu + sigma * eps
data.frame(x = x, y = y)
}
df <- generate_data_C(1000)
plot(df$x, df$y)
generate_data_B <- function(n) {
x <- runif(n, -5, 5)
mu <- sin(2 * x)
sigma <- 0.5 + 0.5 * plogis(x)          # σ hängt von x ab
eps <- rnorm(n)
y <- mu + sigma * eps
data.frame(x = x, y = y)
}
df <- generate_data_B(1000)
plot(df$x, df$y)
generate_data_B <- function(n) {
x <- runif(n, -5, 5)
mu <- sin(2 * x)
sigma <- 0.5 + 0.5 * plogis(x)          # σ hängt von x ab
eps <- rnorm(n)
y <- mu + sigma * eps
data.frame(x = x, y = y)
}
dfb <- generate_data_B(1000)
plot(dfb$x, dfb$y)
generate_data_C <- function(n) {
x <- runif(n, -5, 5)
mu <- sin(2 * x)
sigma <- 0.5 + 0.5 * plogis(x)
eps <- rt(n, df = 3)                    # heavy tails
y <- mu + sigma * eps
data.frame(x = x, y = y)
}
df <- generate_data_C(1000)
plot(df$x, df$y)
load_all()
# Szenario A: nichtlineares µ, konstantes σ
generate_data_A <- function(n) {
x <- runif(n, -1, 1)                   # Feature
mu <- 5 *sin(x)                       # Erwartungswert
sigma <- rep(1, n)                      # konstante Varianz
eps <- rnorm(n)                         # Normalfehler
y <- mu + sigma * eps                   # Zielvariable
data.frame(x = x, y = y)
}
# Szenario B: nichtlineares µ, heteroskedastisches σ
generate_data_B <- function(n) {
x <- runif(n, -5, 5)
mu <- sin(2 * x)
sigma <- 0.5 + 0.5 * plogis(x)          # σ hängt von x ab
eps <- rnorm(n)
y <- mu + sigma * eps
data.frame(x = x, y = y)
}
# Szenario C: wie B, aber heavy tails (t-Verteilung)
generate_data_C <- function(n) {
x <- runif(n, -5, 5)
mu <- sin(2 * x)
sigma <- 0.5 + 0.5 * plogis(x)
eps <- rt(n, df = 3)                    # heavy tails
y <- mu + sigma * eps
data.frame(x = x, y = y)
}
# -------------------------------------
scenarios <- list(
"A" = generate_data_A,
"B" = generate_data_B,
"C" = generate_data_C
)
# -------------------------------------
# Parameter
# -------------------------------------
n_reps <- 3   # klein zum Testen
n <- 500      # Stichprobengröße
# -------------------------------------
# Hauptschleife
# -------------------------------------
for (scn_name in names(scenarios)) {
cat("Starte Szenario:", scn_name, "\n")
gen_fun <- scenarios[[scn_name]]
for (rep_id in 1:n_reps) {
cat("  Replikation:", rep_id, "\n")
set.seed(100 + rep_id)
# 1. Daten generieren
data <- gen_fun(n)   # Dataframe mit x, y
# 2. Split in Train/Val/Test
data_split <- random_split(data$x, normalization = FALSE)
# 3. DataLoader für Training
train_loader <- DataLoader(data_split$train)
val_split <- data_split$validation
# 4. -> Hier käme jetzt das Training
# model <- train(train_loader, ..., val_split, ...)
}
}
load_all()
# Szenario A: nichtlineares µ, konstantes σ
generate_data_A <- function(n) {
x <- runif(n, -1, 1)                   # Feature
mu <- 5 *sin(x)                       # Erwartungswert
sigma <- rep(1, n)                      # konstante Varianz
eps <- rnorm(n)                         # Normalfehler
y <- mu + sigma * eps                   # Zielvariable
data.frame(x = x, y = y)
}
# Szenario B: nichtlineares µ, heteroskedastisches σ
generate_data_B <- function(n) {
x <- runif(n, -5, 5)
mu <- sin(2 * x)
sigma <- 0.5 + 0.5 * plogis(x)          # σ hängt von x ab
eps <- rnorm(n)
y <- mu + sigma * eps
data.frame(x = x, y = y)
}
# Szenario C: wie B, aber heavy tails (t-Verteilung)
generate_data_C <- function(n) {
x <- runif(n, -5, 5)
mu <- sin(2 * x)
sigma <- 0.5 + 0.5 * plogis(x)
eps <- rt(n, df = 3)                    # heavy tails
y <- mu + sigma * eps
data.frame(x = x, y = y)
}
# -------------------------------------
scenarios <- list(
"A" = generate_data_A,
"B" = generate_data_B,
"C" = generate_data_C
)
# -------------------------------------
# Parameter
# -------------------------------------
n_reps <- 3   # klein zum Testen
n <- 500      # Stichprobengröße
# -------------------------------------
# Hauptschleife
# -------------------------------------
for (scn_name in names(scenarios)) {
cat("Starte Szenario:", scn_name, "\n")
gen_fun <- scenarios[[scn_name]]
for (rep_id in 1:n_reps) {
cat("  Replikation:", rep_id, "\n")
set.seed(100 + rep_id)
# 1. Daten generieren
data <- gen_fun(n)   # Dataframe mit x, y
# 2. Split in Train/Val/Test
data_split <- random_split(data$x, normalization = FALSE)
# 3. DataLoader für Training
train_loader <- DataLoader(data_split$train)
val_split <- data_split$validation
# 4. -> Hier käme jetzt das Training
# model <- train(train_loader, ..., val_split, ...)
}
}
load_all()
# Szenario A: nichtlineares µ, konstantes σ
generate_data_A <- function(n) {
x <- runif(n, -1, 1)                   # Feature
mu <- 5 *sin(x)                       # Erwartungswert
sigma <- rep(1, n)                      # konstante Varianz
eps <- rnorm(n)                         # Normalfehler
y <- mu + sigma * eps                   # Zielvariable
data.frame(x = x, y = y)
}
# Szenario B: nichtlineares µ, heteroskedastisches σ
generate_data_B <- function(n) {
x <- runif(n, -5, 5)
mu <- sin(2 * x)
sigma <- 0.5 + 0.5 * plogis(x)          # σ hängt von x ab
eps <- rnorm(n)
y <- mu + sigma * eps
data.frame(x = x, y = y)
}
# Szenario C: wie B, aber heavy tails (t-Verteilung)
generate_data_C <- function(n) {
x <- runif(n, -5, 5)
mu <- sin(2 * x)
sigma <- 0.5 + 0.5 * plogis(x)
eps <- rt(n, df = 3)                    # heavy tails
y <- mu + sigma * eps
data.frame(x = x, y = y)
}
# -------------------------------------
scenarios <- list(
"A" = generate_data_A,
"B" = generate_data_B,
"C" = generate_data_C
)
# -------------------------------------
# Parameter
# -------------------------------------
n_reps <- 3   # klein zum Testen
n <- 500      # Stichprobengröße
# -------------------------------------
# Hauptschleife
# -------------------------------------
for (scn_name in names(scenarios)) {
cat("Starte Szenario:", scn_name, "\n")
gen_fun <- scenarios[[scn_name]]
for (rep_id in 1:n_reps) {
cat("  Replikation:", rep_id, "\n")
set.seed(100 + rep_id)
# 1. Daten generieren
data <- gen_fun(n)   # Dataframe mit x, y
# 2. Split in Train/Val/Test
data_split <- random_split(data["x"], normalization = FALSE)
# 3. DataLoader für Training
train_loader <- DataLoader(data_split$train)
val_split <- data_split$validation
# 4. -> Hier käme jetzt das Training
# model <- train(train_loader, ..., val_split, ...)
}
}
load_all()
data <- abdom
abdom_split <- random_split(abdom['x'], normalization=FALSE)
abdom_targets <- abdom$y
train_abdom <- abdom_split$train
val_abdom <- abdom_split$validation
abdom_loader <- DataLoader(train_abdom, batch_size = 256)
model <- train(abdom_loader, abdom_targets,val_abdom, c(50), optimizer="adam", epochs=50, lr=0.01)
load_all()
data <- abdom
abdom_split <- random_split(abdom['x'], normalization=FALSE)
abdom_targets <- abdom$y
train_abdom <- abdom_split$train
val_abdom <- abdom_split$validation
abdom_loader <- DataLoader(train_abdom, batch_size = 256)
model <- train(abdom_loader, abdom_targets,val_abdom, c(50), optimizer="adam", epochs=50, lr=0.01)
set.seed(42)
n     <- 1000
x     <- runif(n, 0, 10)
mu    <- 5 * sin(x)
sigma <- 0.5 + 0.3 * x
eps   <- rnorm(n, 0, sigma)
y     <- mu + eps
df    <- data.frame(x = x, y = y)
ord   <- order(df$x)
plot(df$x, df$y, pch = 16, cex = 0.6, xlab = "x", ylab = "y", main = "Nicht‐linear + Heteroskedastisch")
n     <- 1000
x     <- runif(n, 0, 10)
mu    <- 5 * sin(x)
sigma <- 0.5 + 0.3 * x
eps   <- rnorm(n, 0, sigma)
y     <- mu + eps
df    <- data.frame(x = x, y = y)
ord   <- order(df$x)
sim_targets <- df$y
train_sim <- sim_split$train
#View(df)
sim_split <- random_split(df['x'], normalization=FALSE)
val_sim <- sim_split$validation
train_sim <- sim_split$train
sim_targets <- df$y
val_sim_targets <- sim_targets[as.integer(rownames(val_sim))]
sim_loader <- DataLoader(train_sim, batch_size = 32)
model3 <- train(sim_loader, sim_targets, t(val_sim), val_sim_targets, c(50),optimizer="adam", epochs=1000, lr=0.01)
# Summary function test without normalization
load_all()
data <- abdom
abdom_split <- random_split(abdom['x'], normalization=FALSE)
abdom_targets <- abdom$y
train_abdom <- abdom_split$train
val_abdom <- abdom_split$validation
abdom_loader <- DataLoader(train_abdom, batch_size = 256)
model <- train(abdom_loader, abdom_targets,val_abdom, hidden_neurons = c(50), optimizer="adam", epochs=50, lr=0.01)
#-------------------------------------------------------------
load_all()
data <- abdom
abdom_split <- random_split(abdom['x'], normalization=FALSE)
abdom_targets <- abdom$y
View(abdom_split)
train_abdom <- abdom_split$train
val_abdom <- abdom_split$validation
abdom_loader <- DataLoader(train_abdom, batch_size = 256)
model <- train(abdom_loader, abdom_targets,val_abdom)
load_all()
data <- abdom
abdom_split <- random_split(abdom['x'], normalization=FALSE)
abdom_targets <- abdom$y
train_abdom <- abdom_split$train
val_abdom <- abdom_split$validation
abdom_loader <- DataLoader(train_abdom, batch_size = 256)
model <- train(abdom_loader, abdom_targets,t(val_abdom))
