lines(x, lower, col = "blue", lty = 2)
lines(abdom$x, upper, col = "blue", lty = 2)
lines(abdom$x, lower, col = "blue", lty = 2)
plot(abdom$x, abdom$y, xlab = "x", ylab = "y", main = "Abdomen Data")
lines(abdom$x, mu, col = "red", lwd = 2)
sigma <- exp(fwd_abdom$log_sigma)
upper <- mu + 1.96 * sigma
lower <- mu - 1.96 * sigma
polygon(
c(abdom$x, rev(abdom$x)),
c(upper, rev(lower)),
col = rgb(0.2, 0.2, 1, alpha = 0.2),
border = NA
)
set.seed(42)
n     <- 500
x     <- runif(n, 0, 10)
mu    <- 5 * sin(x)
sigma <- 0.5 + 0.3 * x
eps   <- rnorm(n, 0, sigma)
y     <- mu + eps
df    <- data.frame(x = x, y = y, mu = mu, sigma = sigma)
ord   <- order(df$x)
plot(df$x, df$y, pch = 16, cex = 0.6, xlab = "x", ylab = "y", main = "Nicht‐linear + Heteroskedastisch")
View(df)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000)
sim_split <- train_val_test(df['x'], normalization=FALSE)
sim_targets <- df$y
train_sim <- sim_split$train
val_sim <- sim_split$validation
val_sim_targets <- sim_targets[as.integer(rownames(val_sim))]
sim_loader <- DataLoader(train_sim)
dimensions <- getLayerDimensions(sim_loader[[1]]$batch, 2, hidden_neurons = 50)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000)
model3
summary(model3)
plot(df$x, df$y, pch = 16, cex = 0.6, xlab = "x", ylab = "y", main = "Nicht‐linear + Heteroskedastisch")
lines(df$x, mu, col = "red", lwd = 2)
df['x']
fwd_sim <- forward_onehidden(t(df['x']), model3$params)
mu_sim <- fwd_sim$mu
plot(df$x, df$y, pch = 16, cex = 0.6, xlab = "x", ylab = "y", main = "Nicht‐linear + Heteroskedastisch")
lines(df$x, mu_sim, col = "red", lwd = 2)
sigma <- exp(fwd_sim$log_sigma)
upper <- mu + 1.96 * sigma
lower <- mu - 1.96 * sigma
polygon(
c(df$x, rev(df$x)),
c(upper, rev(lower)),
col = rgb(0.2, 0.2, 1, alpha = 0.2),
border = NA
)
# Sortierindex berechnen
ord <- order(df$x)
plot(df$x, df$y,
pch   = 16,
cex   = 0.6,
xlab  = "x",
ylab  = "y",
main  = "Nicht‐linear + Heteroskedastisch")
lines(df$x[ord], mu_sim[ord],
col = "red",
lwd = 2)
upper <- mu_sim + 1.96 * sigma_sim
lower <- mu_sim - 1.96 * sigma_sim
sigma_sim <- exp(fwd_sim$log_sigma)
upper <- mu_sim + 1.96 * sigma_sim
lower <- mu_sim - 1.96 * sigma_sim
polygon(
x    = c(df$x[ord], rev(df$x[ord])),
y    = c(upper[ord], rev(lower[ord])),
col   = rgb(1, 0, 0, alpha = 0.2),
border = NA
)
load_all()
set.seed(42)
n     <- 500
x     <- runif(n, 0, 10)
mu    <- 5 * sin(x)
sigma <- 0.5 + 0.3 * x
eps   <- rnorm(n, 0, sigma)
y     <- mu + eps
df    <- data.frame(x = x, y = y, mu = mu, sigma = sigma)
ord   <- order(df$x)
plot(df$x, df$y, pch = 16, cex = 0.6, xlab = "x", ylab = "y", main = "Nicht‐linear + Heteroskedastisch")
sim_split <- train_val_test(df['x'], normalization=FALSE)
sim_targets <- df$y
train_sim <- sim_split$train
val_sim <- sim_split$validation
val_sim_targets <- sim_targets[as.integer(rownames(val_sim))]
sim_loader <- DataLoader(train_sim)
dimensions <- getLayerDimensions(sim_loader[[1]]$batch, 2, hidden_neurons = 50)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000)
model3
summary(model3)
fwd_sim <- forward_onehidden(t(df['x']), model3$params)
mu_sim <- fwd_sim$mu
sigma_sim <- exp(fwd_sim$log_sigma)
fwd_sim <- forward_onehidden(df['x'], model3$params)
fwd_sim <- forward_onehidden(t(df['x']), model3$params)
mu_sim <- fwd_sim$mu
sigma_sim <- exp(fwd_sim$log_sigma)
# Sortierindex berechnen
ord <- order(df$x)
plot(df$x, df$y,
pch   = 16,
cex   = 0.6,
xlab  = "x",
ylab  = "y",
main  = "Nicht‐linear + Heteroskedastisch")
lines(df$x[ord], mu_sim[ord],
col = "red",
lwd = 2)
upper <- mu_sim + 1.96 * sigma_sim
lower <- mu_sim - 1.96 * sigma_sim
polygon(
x    = c(df$x[ord], rev(df$x[ord])),
y    = c(upper[ord], rev(lower[ord])),
col   = rgb(1, 0, 0, alpha = 0.2),
border = NA
)
set.seed(42)
n <- 500
beta <- 2
sigma0 <- 0.5
# 1) Simuliere x
x <- abs(rnorm(n, mean = 0, sd = 1))
# 2) Berechne für jede x_i die Fehler‐Std-Dev
sigma_x <- sigma0 * x
# 3) Ziehe heteroskedastische Fehler
eps <- rnorm(n, mean = 0, sd = sigma_x)
# 4) Erzeuge y
y <- beta * x + eps
# Kurzer Blick auf Varianz in Abhängigkeit von x
plot(x, y,
xlab = "x",
ylab = "y",
main = "Heteroskedastie")
dataframe <- as.data.frame(cbind(x, y))
View(dataframe)
colnames(dataframe) <- c("unab", "abh")
split <- train_val_test(dataframe["unab"])
train <- split$train
val <- split$val
test <- split$test
nrow(dataframe) == nrow(test)+nrow(train)+nrow(val)
train_loader <- DataLoader(split$train)
targets <- dataframe$abh
val_targets <- targets[as.integer(rownames(val))]
dimensions <- getLayerDimensions(train_loader[[1]]$batch, 2, hidden_neurons = 3)
train_network_val_adam(train_loader, targets, dimensions, t(val), val_targets)
train_network(train_loader,
targets,
dimensions)
install.packages("ellmer")
source("~/Schreibtisch/Studium/ASP/asp25nnet/testing.R")
sim_loader[[1]]$batch
batch <- sim_loader[[1]]$batch
dim(batch)
batch_forward <- forward_onehidden(t(batch), model3$params)
batch_forward <- forward_onehidden(batch, model3$params)
batch_forward
neg_log_lik(yb, as.numeric(batch_forward$mu), as.numeric(batch_forward$log_sigma),reduction = "mean")
batch
sim_loader[[1]]$idx
y_targ <- y[sim_loader[[1]]$idx]
neg_log_lik(y_targ, as.numeric(batch_forward$mu), as.numeric(batch_forward$log_sigma),reduction = "mean")
neg_log_lik(y_targ, as.numeric(batch_forward$mu), as.numeric(batch_forward$log_sigma),reduction = "raw")
mean(neg_log_lik(y_targ, as.numeric(batch_forward$mu), as.numeric(batch_forward$log_sigma),reduction = "raw"))
neg_log_lik(y_targ, as.numeric(batch_forward$mu), as.numeric(batch_forward$log_sigma),reduction = "sum")
numeric(2)
test_hist <- numeric(2)
test_hist[1] <- neg_log_lik(y_targ, as.numeric(batch_forward$mu), as.numeric(batch_forward$log_sigma), reduction = "raw")
test_hist[1] <- neg_log_lik(y_targ, as.numeric(batch_forward$mu), as.numeric(batch_forward$log_sigma), reduction = "sum")
test_hist <- list(2)
test_hist
test_hist[[1]] <- neg_log_lik(y_targ, as.numeric(batch_forward$mu), as.numeric(batch_forward$log_sigma), reduction = "sum")
test_hist
test_hist <- list()
test_hist[[1]] <- neg_log_lik(y_targ, as.numeric(batch_forward$mu), as.numeric(batch_forward$log_sigma), reduction = "raw")
test_hist
test_hist[[2]] <- neg_log_lik(y_targ, as.numeric(batch_forward$mu), as.numeric(batch_forward$log_sigma), reduction = "mean")
test_hist
test_hist <- list()
test_hist[[1]] <- neg_log_lik(y_targ, as.numeric(batch_forward$mu), as.numeric(batch_forward$log_sigma), reduction = "raw")
test_hist
test_hist[[2]] <- neg_log_lik(y_targ, as.numeric(batch_forward$mu), as.numeric(batch_forward$log_sigma), reduction = "raw")
test_hist
mean(test_hist)
load_all()
rlang::last_trace()
source("~/Schreibtisch/Studium/ASP/asp25nnet/testing.R")
model2 <- train(abdom_loader, abdom_targets, dimensions, t(val_abdom), val_abdom_targets, optimizer="sgd", epochs=1000)
model2 <- train(abdom_loader, abdom_targets, dimensions, t(val_abdom), val_abdom_targets, optimizer="adam", epochs=1000)
model2
summary(model2)
summary(model3)
dimensions <- getLayerDimensions(abdom_loader[[1]]$batch, 2, hidden_neurons = 10)
model2 <- train(abdom_loader, abdom_targets, dimensions, t(val_abdom), val_abdom_targets, optimizer="adam", epochs=1000)
model2
summary(model2)
dimensions <- getLayerDimensions(abdom_loader[[1]]$batch, 2, hidden_neurons = 3)
model2 <- train(abdom_loader, abdom_targets, dimensions, t(val_abdom), val_abdom_targets, optimizer="adam", epochs=1000)
model2
summary(model2)
dimensions <- getLayerDimensions(sim_loader[[1]]$batch, 2, hidden_neurons = 50)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000)
model3
summary(model3)
dimensions <- getLayerDimensions(sim_loader[[1]]$batch, 2, hidden_neurons = 3)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000)
model3
summary(model3)
dimensions <- getLayerDimensions(sim_loader[[1]]$batch, 2, hidden_neurons = 10)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000)
model3
summary(model3)
set.seed(42)
n     <- 10000
x     <- runif(n, 0, 10)
mu    <- 5 * sin(x)
sigma <- 0.5 + 0.3 * x
eps   <- rnorm(n, 0, sigma)
y     <- mu + eps
df    <- data.frame(x = x, y = y, mu = mu, sigma = sigma)
ord   <- order(df$x)
plot(df$x, df$y, pch = 16, cex = 0.6, xlab = "x", ylab = "y", main = "Nicht‐linear + Heteroskedastisch")
View(df)
sim_split <- random_split(df['x'], normalization=FALSE)
sim_targets <- df$y
train_sim <- sim_split$train
val_sim <- sim_split$validation
val_sim_targets <- sim_targets[as.integer(rownames(val_sim))]
sim_loader <- DataLoader(train_sim)
dimensions <- getLayerDimensions(sim_loader[[1]]$batch, 2, hidden_neurons = 10)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000)
model3
summary(model3)
sim_loader <- DataLoader(train_sim, batch_size = 256)
dimensions <- getLayerDimensions(sim_loader[[1]]$batch, 2, hidden_neurons = 10)
sim_loader[[1]]$batch
dimensions
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000)
model3
summary(model3)
sim_loader <- DataLoader(train_sim, batch_size = 256)
dimensions <- getLayerDimensions(sim_loader[[1]]$batch, 2, hidden_neurons = 50)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000)
model3
summary(model3)
fwd_sim <- forward_onehidden(t(df['x']), model3$params)
mu_sim <- fwd_sim$mu
sigma_sim <- exp(fwd_sim$log_sigma)
# Sortierindex berechnen
ord <- order(df$x)
plot(df$x, df$y,
pch   = 16,
cex   = 0.6,
xlab  = "x",
ylab  = "y",
main  = "Nicht‐linear + Heteroskedastisch")
lines(df$x[ord], mu_sim[ord],
col = "red",
lwd = 2)
upper
upper <- mu_sim + 1.96 * sigma_sim
lower <- mu_sim - 1.96 * sigma_sim
polygon(
x    = c(df$x[ord], rev(df$x[ord])),
y    = c(upper[ord], rev(lower[ord])),
col   = rgb(1, 0, 0, alpha = 0.2),
border = NA
)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000, lr=0.001)
model3
summary(model3)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000, lr=0.0001)
model3
summary(model3)
length(10)
devtools::document()
paste0("W", 1)
load_all()
set.seed(42)
n     <- 10000
x     <- runif(n, 0, 10)
mu    <- 5 * sin(x)
sigma <- 0.5 + 0.3 * x
eps   <- rnorm(n, 0, sigma)
y     <- mu + eps
df    <- data.frame(x = x, y = y, mu = mu, sigma = sigma)
ord   <- order(df$x)
plot(df$x, df$y, pch = 16, cex = 0.6, xlab = "x", ylab = "y", main = "Nicht‐linear + Heteroskedastisch")
View(df)
sim_split <- random_split(df['x'], normalization=FALSE)
sim_targets <- df$y
train_sim <- sim_split$train
val_sim <- sim_split$validation
val_sim_targets <- sim_targets[as.integer(rownames(val_sim))]
sim_loader <- DataLoader(train_sim, batch_size = 256)
dimensions <- getLayerDimensions(sim_loader[[1]]$batch, 2, hidden_neurons = 50)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000, lr=0.0001)
model3
summary(model3)
fwd_sim <- forward_onehidden(t(df['x']), model3$params)
mu_sim <- fwd_sim$mu
sigma_sim <- exp(fwd_sim$log_sigma)
# Sortierindex berechnen
ord <- order(df$x)
plot(df$x, df$y,
pch   = 16,
cex   = 0.6,
xlab  = "x",
ylab  = "y",
main  = "Nicht‐linear + Heteroskedastisch")
lines(df$x[ord], mu_sim[ord],
col = "red",
lwd = 2)
upper <- mu_sim + 1.96 * sigma_sim
lower <- mu_sim - 1.96 * sigma_sim
polygon(
x    = c(df$x[ord], rev(df$x[ord])),
y    = c(upper[ord], rev(lower[ord])),
col   = rgb(1, 0, 0, alpha = 0.2),
border = NA
)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000, lr=0.001)
model3
summary(model3)
fwd_sim <- forward_onehidden(t(df['x']), model3$params)
mu_sim <- fwd_sim$mu
sigma_sim <- exp(fwd_sim$log_sigma)
# Sortierindex berechnen
ord <- order(df$x)
plot(df$x, df$y,
pch   = 16,
cex   = 0.6,
xlab  = "x",
ylab  = "y",
main  = "Nicht‐linear + Heteroskedastisch")
lines(df$x[ord], mu_sim[ord],
col = "red",
lwd = 2)
upper <- mu_sim + 1.96 * sigma_sim
lower <- mu_sim - 1.96 * sigma_sim
polygon(
x    = c(df$x[ord], rev(df$x[ord])),
y    = c(upper[ord], rev(lower[ord])),
col   = rgb(1, 0, 0, alpha = 0.2),
border = NA
)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000, lr=0.01)
model3
summary(model3)
fwd_sim <- forward_onehidden(t(df['x']), model3$params)
mu_sim <- fwd_sim$mu
sigma_sim <- exp(fwd_sim$log_sigma)
# Sortierindex berechnen
ord <- order(df$x)
plot(df$x, df$y,
pch   = 16,
cex   = 0.6,
xlab  = "x",
ylab  = "y",
main  = "Nicht‐linear + Heteroskedastisch")
lines(df$x[ord], mu_sim[ord],
col = "red",
lwd = 2)
upper <- mu_sim + 1.96 * sigma_sim
lower <- mu_sim - 1.96 * sigma_sim
polygon(
x    = c(df$x[ord], rev(df$x[ord])),
y    = c(upper[ord], rev(lower[ord])),
col   = rgb(1, 0, 0, alpha = 0.2),
border = NA
)
# Test for variable layer sizes
getLayerDimensions()
# Test for variable layer sizes
getLayerDimensions(train_loader[[1]]$batch, out_dim = 2, hidden_neurons = c(50, 30, 20))
# Test for variable layer sizes
getLayerDimensions(sim_loader[[1]]$batch, out_dim = 2, hidden_neurons = c(50, 30, 20))
# Test for variable layer sizes
getLayerDimensions_variable(sim_loader[[1]]$batch, out_dim = 2, hidden_neurons = c(50, 30, 20))
# Test for variable layer sizes
getLayerDimensions_variable(sim_loader[[1]]$batch, out_dim = 2, hidden_neurons = c(50))
# Test for variable layer sizes
multi_layer_dims <- getLayerDimensions_variable(sim_loader[[1]]$batch, out_dim = 2, hidden_neurons = c(50, 30, 20))
init_params_variable(multi_layer_dims)
dim(sim_loader[[1]]$batch)
dim(sim_loader[[1]]$batch)[1]
params <- init_params_variable(multi_layer_dims)
class(params)
lapply(params, dim)
set.seed(42)
n     <- 10000
x     <- runif(n, 0, 10)
mu    <- 5 * sin(x)
sigma <- 0.5 + 0.3 * x
eps   <- rnorm(n, 0, sigma)
y     <- mu + eps
df    <- data.frame(x = x, y = y, mu = mu, sigma = sigma)
ord   <- order(df$x)
plot(df$x, df$y, pch = 16, cex = 0.6, xlab = "x", ylab = "y", main = "Nicht‐linear + Heteroskedastisch")
View(df)
sim_split <- random_split(df['x'], normalization=FALSE)
sim_targets <- df$y
train_sim <- sim_split$train
val_sim <- sim_split$validation
val_sim_targets <- sim_targets[as.integer(rownames(val_sim))]
sim_loader <- DataLoader(train_sim, batch_size = 256)
sim_split <- random_split(df['x'], normalization=FALSE)
load_all()
sim_split <- random_split(df['x'], normalization=FALSE)
sim_targets <- df$y
train_sim <- sim_split$train
val_sim <- sim_split$validation
val_sim_targets <- sim_targets[as.integer(rownames(val_sim))]
sim_loader <- DataLoader(train_sim, batch_size = 256)
dimensions <- getLayerDimensions(sim_loader[[1]]$batch, 2, hidden_neurons = 50)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000, lr=0.01)
model3
summary(model3)
fwd_sim <- forward_onehidden(t(df['x']), model3$params)
mu_sim <- fwd_sim$mu
sigma_sim <- exp(fwd_sim$log_sigma)
# Sortierindex berechnen
ord <- order(df$x)
plot(df$x, df$y,
pch   = 16,
cex   = 0.6,
xlab  = "x",
ylab  = "y",
main  = "Nicht‐linear + Heteroskedastisch")
lines(df$x[ord], mu_sim[ord],
col = "red",
lwd = 2)
upper <- mu_sim + 1.96 * sigma_sim
lower <- mu_sim - 1.96 * sigma_sim
polygon(
x    = c(df$x[ord], rev(df$x[ord])),
y    = c(upper[ord], rev(lower[ord])),
col   = rgb(1, 0, 0, alpha = 0.2),
border = NA
)
# Test for variable layer sizes and multiple inputs
multi_layer_dims <- getLayerDimensions_variable(sim_loader[[1]]$batch, out_dim = 2, hidden_neurons = c(50, 30, 20))
dim(sim_loader[[1]]$batch)[1]
params <- init_params_variable(multi_layer_dims)
lapply(params, dim)
forward_variable(sim_loader[[1]]$batch, params)
forward_variable(t(sim_loader[[1]]$batch), params)
forward_variable(sim_loader[[1]]$batch, params)
attr(params, "architecture")
matrix(0, nrow = 50, ncol = 1)
params
params$W4
class(params$W4)
class(params[["W4"]])
sample(5)
load_all()
set.seed(42)
n     <- 1000
x     <- runif(n, 0, 10)
mu    <- 5 * sin(x)
sigma <- 0.5 + 0.3 * x
eps   <- rnorm(n, 0, sigma)
y     <- mu + eps
df    <- data.frame(x = x, y = y, mu = mu, sigma = sigma)
ord   <- order(df$x)
plot(df$x, df$y, pch = 16, cex = 0.6, xlab = "x", ylab = "y", main = "Nicht‐linear + Heteroskedastisch")
View(df)
sim_split <- random_split(df['x'], normalization=FALSE)
sim_targets <- df$y
train_sim <- sim_split$train
val_sim <- sim_split$validation
val_sim_targets <- sim_targets[as.integer(rownames(val_sim))]
sim_loader <- DataLoader(train_sim, batch_size = 256)
dimensions <- getLayerDimensions(sim_loader[[1]]$batch, 2, hidden_neurons = 50)
model3 <- train(sim_loader, sim_targets, dimensions, t(val_sim), val_sim_targets, optimizer="adam", epochs=1000, lr=0.01)
model3
summary(model3)
fwd_sim <- forward_onehidden(t(df['x']), model3$params)
mu_sim <- fwd_sim$mu
sigma_sim <- exp(fwd_sim$log_sigma)
# Sortierindex berechnen
ord <- order(df$x)
plot(df$x, df$y,
pch   = 16,
cex   = 0.6,
xlab  = "x",
ylab  = "y",
main  = "Nicht‐linear + Heteroskedastisch")
lines(df$x[ord], mu_sim[ord],
col = "red",
lwd = 2)
upper <- mu_sim + 1.96 * sigma_sim
lower <- mu_sim - 1.96 * sigma_sim
polygon(
x    = c(df$x[ord], rev(df$x[ord])),
y    = c(upper[ord], rev(lower[ord])),
col   = rgb(1, 0, 0, alpha = 0.2),
border = NA
)
# Test for variable layer sizes and multiple inputs
multi_layer_dims <- getLayerDimensions_variable(sim_loader[[1]]$batch, out_dim = 2, hidden_neurons = c(50, 30, 20))
dim(sim_loader[[1]]$batch)[1]
params <- init_params_variable(multi_layer_dims)
lapply(params, dim)
params$b1
params$b1 %*% matrix(1, nrow = 1, ncol = 3)
params$b1+2 %*% matrix(1, nrow = 1, ncol = 3)
