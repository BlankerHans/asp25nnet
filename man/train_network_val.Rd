% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_network_val.R
\name{train_network_val}
\alias{train_network_val}
\title{Train a Single-Hidden-Layer Neural Network with Validation Loss Monitoring}
\usage{
train_network_val(
  train_loader,
  targets,
  dimensions,
  validation_X,
  validation_y,
  epochs = 100,
  lr = 0.01
)
}
\arguments{
\item{train_loader}{A list of batches. Each batch must be a list containing:
\code{$batch}: Input matrix of shape (observations × features),
\code{$idx}: Integer indices corresponding to the observations in the original dataset.}

\item{targets}{Numeric vector of target values for all training observations.}

\item{dimensions}{A list specifying the network dimensions, e.g., as returned by \code{getLayerDimensions()}.}

\item{validation_X}{Numeric matrix of validation inputs (observations × features).}

\item{validation_y}{Numeric vector of target values for validation observations.}

\item{epochs}{Integer specifying the number of training epochs. Default is 100.}

\item{lr}{Numeric learning rate. Default is 0.01.}
}
\value{
A list containing:
\itemize{
\item \code{params}: A list of trained network parameters (weights and biases).
\item \code{train_loss}: Numeric vector of average training loss per epoch.
\item \code{val_loss}: Numeric vector of validation loss per epoch.
}
}
\description{
Trains a feed-forward neural network with one hidden layer using stochastic gradient descent,
and records both training and validation loss per epoch.
}
\details{
For each epoch, the function iterates over all training batches, performs a forward pass,
computes the negative log-likelihood loss, backpropagates gradients, and updates parameters.
After all batches are processed, the model is evaluated once on the full validation set
to compute the validation loss. Both training and validation losses are recorded.
}
\examples{
# Example usage:
data <- matrix(rnorm(100 * 10), nrow = 100)
targets <- rnorm(100)
# Split your data here into train/validation
train_loader <- create_batches(data[1:80, ], batch_size = 20)
dims <- getLayerDimensions(data, out_dim = 2, hidden_neurons = 5)
validation_X <- data[81:100, ]
validation_y <- targets[81:100]
result <- train_network(train_loader, targets[1:80], dims, validation_X, validation_y,
                        epochs = 10, lr = 0.01)

}
