% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_namls.R
\name{train_namls}
\alias{train_namls}
\title{Train NAMLS}
\usage{
train_namls(
  train_loader,
  targets,
  n_features,
  hidden_neurons = c(250, 50, 25),
  val_split = NULL,
  val_targets = NULL,
  epochs = 100,
  lr = 0.01,
  optimizer = c("adam", "sgd"),
  dropout_rate = 0.5,
  beta1 = 0.9,
  beta2 = 0.999,
  eps = 1e-08,
  lr_decay = 0.95,
  lr_patience = 10,
  verbose = TRUE,
  es_patience = 20,
  es_min_delta = 0,
  es_warmup = 50,
  restore_best_weights = TRUE
)
}
\arguments{
\item{train_loader}{DataLoader mit Trainingsdaten}

\item{targets}{Alle Zielwerte}

\item{n_features}{Anzahl Features}

\item{hidden_neurons}{Hidden Layer Größen}

\item{val_split}{Validierungsdaten (optional)}

\item{val_targets}{Validierungsziele (optional)}

\item{epochs}{Anzahl Epochen}

\item{lr}{Lernrate}

\item{optimizer}{"sgd" oder "adam"}

\item{dropout_rate}{Dropout Rate (Paper: 0.5 für kleine Datensätze)}

\item{beta1}{Adam Parameter}

\item{beta2}{Adam Parameter}

\item{eps}{Adam Parameter}

\item{lr_decay}{Learning rate decay factor}

\item{lr_patience}{Epochs to wait before decay}

\item{verbose}{Fortschritt anzeigen}

\item{es_patience}{Epochs without improvement (Default 20)}

\item{es_min_delta}{Improvement Criterion (Default 0)}

\item{es_warmup}{Epoch when early stopping should start (Default 50)}

\item{restore_best_weights}{Do you want to store best weights? (Default TRUE)}
}
\value{
Trainiertes Modell
}
\description{
Train NAMLS
}
